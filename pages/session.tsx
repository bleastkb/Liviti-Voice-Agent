/**
 * Session é¡µé¢
 * ä¸»è¦çš„ä¼šè¯ç•Œé¢ï¼ŒåŒ…å«éº¦å…‹é£æŒ‰é’®ã€æ¶ˆæ¯åˆ—è¡¨å’Œå®‰å…¨æ¨ªå¹…
 */

import { useState, useRef, useEffect, FormEvent } from 'react';
import { useRouter } from 'next/router';
import Head from 'next/head';
import { Message, SessionState, SafetyLevel, MicroAction, MusicRequest, MusicPlayerInstance } from '@/types';
import MicButton from '@/components/MicButton';
import MessageList from '@/components/MessageList';
import SafetyBanner from '@/components/SafetyBanner';
import { transcribeAudio, getAIResponse, checkSafetyLevel, playAssistantVoice, stopAssistantVoice } from '@/lib/api';
import { buildMicroActionMessage } from '@/lib/prompts';
import { generateSessionId } from '@/lib/logger';

export default function SessionPage() {
  const router = useRouter();
  const [sessionId] = useState(() => generateSessionId()); // Generate once per session
  const [messages, setMessages] = useState<Message[]>([]);
  const [sessionState, setSessionState] = useState<SessionState>('idle');
  const [safetyLevel, setSafetyLevel] = useState<SafetyLevel>('safe');
  const [currentMicroActions, setCurrentMicroActions] = useState<MicroAction[]>([]);
  const [showSafetyBanner, setShowSafetyBanner] = useState(false);
  const [micError, setMicError] = useState<string | null>(null);
  const [micReady, setMicReady] = useState(false);
  const [typedMessage, setTypedMessage] = useState('');
  
  // Music player instances rendered inline with the conversation
  const [musicPlayers, setMusicPlayers] = useState<MusicPlayerInstance[]>([]);
  
  // ç”¨äºå­˜å‚¨å½•éŸ³çš„å¼•ç”¨
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const streamRef = useRef<MediaStream | null>(null);

  // ç”Ÿæˆå”¯ä¸€ID
  const generateId = () => `msg-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;

  // ä½¿ç”¨ChromeåŸç”Ÿæ–¹æ³•æ£€æŸ¥éº¦å…‹é£æƒé™çŠ¶æ€
  const checkMicrophonePermission = async (): Promise<PermissionState | null> => {
    if (typeof window === 'undefined' || !navigator || !navigator.permissions) {
      return null;
    }

    try {
      // ChromeåŸç”Ÿæƒé™æŸ¥è¯¢API
      const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
      return result.state;
    } catch (error) {
      // æŸäº›æµè§ˆå™¨å¯èƒ½ä¸æ”¯æŒpermissions APIï¼Œè¿”å›null
      console.log('Permissions API not supported:', error);
      return null;
    }
  };

  // ä½¿ç”¨ChromeåŸç”Ÿæ–¹æ³•è¯·æ±‚éº¦å…‹é£æƒé™
  const requestMicrophoneAccess = async (): Promise<MediaStream | null> => {
    // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
    if (typeof window === 'undefined') {
      return null;
    }

    // æ£€æŸ¥HTTPSæˆ–localhostï¼ˆChromeè¦æ±‚ï¼‰
    const isSecureContext = window.isSecureContext || 
                           window.location.protocol === 'https:' || 
                           window.location.hostname === 'localhost' || 
                           window.location.hostname === '127.0.0.1';
    
    if (!isSecureContext) {
      setMicError('Microphone access requires a secure connection (HTTPS). Please access this site via HTTPS or localhost.');
      setMicReady(false);
      return null;
    }

    // æ£€æŸ¥Chrome MediaDevices APIæ”¯æŒ
    if (!navigator || !navigator.mediaDevices || typeof navigator.mediaDevices.getUserMedia !== 'function') {
      setMicError('Your browser does not support microphone access. Please use Chrome or another modern browser.');
      setMicReady(false);
      return null;
    }

    try {
      // å…ˆæ£€æŸ¥æƒé™çŠ¶æ€ï¼ˆChromeåŸç”Ÿæ–¹æ³•ï¼‰
      const permissionState = await checkMicrophonePermission();
      
      if (permissionState === 'denied') {
        setMicError('Microphone permission was denied. Please enable it in Chrome settings: Settings > Privacy and security > Site Settings > Microphone');
        setMicReady(false);
        return null;
      }

      // ChromeåŸç”Ÿæ–¹æ³•ï¼šè¯·æ±‚éº¦å…‹é£è®¿é—®
      // ä½¿ç”¨Chromeæ¨èçš„éŸ³é¢‘çº¦æŸé…ç½®
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100, // Chromeæ¨èé‡‡æ ·ç‡
          channelCount: 1    // å•å£°é“
        }
      });

      // éªŒè¯streamæ˜¯å¦æœ‰æ•ˆ
      if (!stream || stream.getAudioTracks().length === 0) {
        throw new Error('No audio tracks available');
      }

      streamRef.current = stream;
      setMicReady(true);
      setMicError(null);
      console.log('Microphone access granted via Chrome native API');
      
      return stream;
    } catch (error: any) {
      console.error('Failed to access microphone:', error);
      setMicReady(false);
      
      // Chromeç‰¹å®šçš„é”™è¯¯å¤„ç†
      let errorMessage = 'Unable to access microphone. ';
      
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        errorMessage += 'Microphone permission was denied. ';
        errorMessage += 'In Chrome: Click the lock icon (ğŸ”’) or microphone icon (ğŸ¤) in the address bar, then select "Allow". ';
        errorMessage += 'Or go to Chrome Settings > Privacy and security > Site Settings > Microphone to manage permissions.';
      } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
        errorMessage += 'No microphone found. Please connect a microphone and try again.';
      } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
        errorMessage += 'Microphone is being used by another application. Please close other apps using the microphone.';
      } else if (error.name === 'OverconstrainedError') {
        errorMessage += 'Microphone does not support the requested constraints. Trying with default settings...';
        // å°è¯•ä½¿ç”¨é»˜è®¤è®¾ç½®
        try {
          const defaultStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          streamRef.current = defaultStream;
          setMicReady(true);
          setMicError(null);
          return defaultStream;
        } catch (defaultError) {
          errorMessage = 'Failed to access microphone with default settings.';
        }
      } else {
        errorMessage += `Error: ${error.message || 'Unknown error'}. Please check your browser permissions and try again.`;
      }
      
      setMicError(errorMessage);
      return null;
    }
  };

  // é¡µé¢åŠ è½½æ—¶ç«‹å³è¯·æ±‚éº¦å…‹é£æƒé™
  useEffect(() => {
    // å»¶è¿Ÿä¸€ç‚¹è¯·æ±‚ï¼Œç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
    const timer = setTimeout(() => {
      requestMicrophoneAccess();
    }, 100);

    return () => {
      clearTimeout(timer);
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
    };
  }, []);

  // å¼€å§‹å½•éŸ³
  const handleStartRecording = async () => {
    // åœæ­¢æ­£åœ¨æ’­æ”¾çš„è¯­éŸ³è¾“å‡º
    stopAssistantVoice();

    // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
    if (typeof window === 'undefined' || !navigator || !navigator.mediaDevices || typeof navigator.mediaDevices.getUserMedia !== 'function') {
      setMicError('Your browser does not support microphone access. Please use a modern browser like Chrome, Firefox, or Safari.');
      setSessionState('idle');
      return;
    }

    // å¦‚æœéº¦å…‹é£æœªå‡†å¤‡å¥½ï¼Œä½¿ç”¨ChromeåŸç”Ÿæ–¹æ³•é‡æ–°è¯·æ±‚æƒé™
    if (!micReady || !streamRef.current) {
      const stream = await requestMicrophoneAccess();
      if (!stream) {
        setSessionState('idle');
        return;
      }
    }

    try {
      const stream = streamRef.current;
      if (!stream) {
        throw new Error('No microphone stream available');
      }

      // æµè§ˆå™¨æ˜¯å¦æ”¯æŒ MediaRecorder
      if (typeof window === 'undefined' || typeof (window as any).MediaRecorder === 'undefined') {
        setMicError(
          'Your browser does not support audio recording via MediaRecorder. Please use the latest version of Chrome or Edge on desktop.'
        );
        setSessionState('idle');
        return;
      }

      const MediaRecorderConstructor: typeof MediaRecorder = (window as any).MediaRecorder;

      // é€‰æ‹©ä¸€ä¸ªæµè§ˆå™¨æ”¯æŒçš„éŸ³é¢‘ç¼–ç æ ¼å¼ï¼Œé¿å… MediaRecorder.start æŠ› NotSupportedError
      const candidateTypes = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/ogg;codecs=opus',
        'audio/mp4',
      ];

      let selectedOptions: MediaRecorderOptions | undefined = undefined;
      if (typeof MediaRecorderConstructor.isTypeSupported === 'function') {
        for (const type of candidateTypes) {
          if (MediaRecorderConstructor.isTypeSupported(type)) {
            selectedOptions = { mimeType: type };
            break;
          }
        }
      }

      let mediaRecorder: MediaRecorder;
      try {
        mediaRecorder = selectedOptions
          ? new MediaRecorderConstructor(stream, selectedOptions)
          : new MediaRecorderConstructor(stream);
      } catch (err: any) {
        console.error('Failed to construct MediaRecorder:', err);
        setMicError(
          'Your browser does not support the required audio format for recording. Please try using Chrome on desktop.'
        );
        setSessionState('idle');
        return;
      }

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        await processAudio(audioBlob);
        // æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œåœæ­¢streamï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦ä¿æŒå®ƒä»¥ä¾¿åç»­å½•éŸ³
      };

      try {
        mediaRecorder.start();
      } catch (err: any) {
        console.error('Failed to start MediaRecorder:', err);
        if (err?.name === 'NotSupportedError') {
          setMicError(
            'Recording is not supported with the current browser or audio configuration. Please try using the latest Chrome on desktop, and make sure this page is opened via HTTPS or localhost.'
          );
        } else {
          setMicError('Failed to start recording. Please check your microphone and browser permissions, then try again.');
        }
        setSessionState('idle');
        return;
      }
      setSessionState('recording');
    } catch (error: any) {
      console.error('Failed to start recording:', error);
      setSessionState('idle');
      setMicError('Failed to start recording. Please try again.');
    }
  };

  // åœæ­¢å½•éŸ³
  const handleStopRecording = () => {
    if (mediaRecorderRef.current && sessionState === 'recording') {
      mediaRecorderRef.current.stop();
      setSessionState('processing');
    }
  };

  const processUserText = async (
    text: string,
    options?: { metadata?: Record<string, any>; interactionType?: 'user_message' | 'micro_action_click' }
  ) => {
    try {
      const trimmed = text.trim();
      if (!trimmed) {
        return;
      }

      const userMessage: Message = {
        id: generateId(),
        role: 'user',
        content: trimmed,
        timestamp: new Date(),
      };
      setMessages((prev) => [...prev, userMessage]);

      setSessionState('responding');
      const conversationHistory = [...messages, userMessage].map((m) => ({
        role: m.role,
        content: m.content,
      }));

      const [safety, aiResponse] = await Promise.all([
        checkSafetyLevel(trimmed),
        getAIResponse(trimmed, conversationHistory, {
          sessionId,
          interactionType: options?.interactionType || 'user_message',
          metadata: {
            ...options?.metadata,
            source: options?.metadata?.source || 'text_input',
          },
        }),
      ]);

      setSafetyLevel(safety);
      if (safety !== 'safe') {
        setShowSafetyBanner(true);
      }

      const assistantMessage: Message = {
        id: generateId(),
        role: 'assistant',
        content: aiResponse.message,
        timestamp: new Date(),
        references: aiResponse.references,
      };
      setMessages((prev) => [...prev, assistantMessage]);

      playAssistantVoice(aiResponse.message).catch((err) => {
        console.error('Failed to play assistant voice:', err);
      });

      if (aiResponse.microActions) {
        setCurrentMicroActions(aiResponse.microActions);
      }

      if (aiResponse.musicRequest?.shouldPlay) {
        handleMusicRequest(aiResponse.musicRequest, assistantMessage.id);
      }

      setSessionState('idle');
    } catch (error) {
      console.error('Error processing user text:', error);
      setSessionState('idle');
      alert('Failed to process your message. Please try again.');
    }
  };

  // å¤„ç†éŸ³é¢‘ï¼šè½¬å½• -> AIå“åº”
  const processAudio = async (audioBlob: Blob) => {
    try {
      const transcript = await transcribeAudio(audioBlob);
      await processUserText(transcript, { metadata: { source: 'voice_input' } });
    } catch (error) {
      console.error('Error processing audio:', error);
      setSessionState('idle');
      alert('Error processing audio. Please try again.');
    }
  };

  const handleSubmitTypedMessage = async (event?: FormEvent<HTMLFormElement>) => {
    event?.preventDefault();
    if (sessionState !== 'idle') {
      return;
    }
    const messageToSend = typedMessage.trim();
    if (!messageToSend) {
      return;
    }
    setTypedMessage('');
    await processUserText(messageToSend, { metadata: { source: 'text_input' } });
  };

  // å¤„ç† Micro-Action ç‚¹å‡»ï¼šåŸºäºé€‰ä¸­çš„ action ç”Ÿæˆ LLM å›å¤
  const handleMicroActionClick = async (action: MicroAction) => {
    if (sessionState !== 'idle') {
      return; // å¦‚æœæ­£åœ¨å¤„ç†ä¸­ï¼Œå¿½ç•¥ç‚¹å‡»
    }

    try {
      setSessionState('responding');

      // æ„å»ºåŸºäº Micro-Action çš„ç”¨æˆ·æ¶ˆæ¯
      const conversationHistory = messages.map((m) => ({
        role: m.role,
        content: m.content,
      }));

      const microActionMessage = buildMicroActionMessage(action, conversationHistory);

      // è°ƒç”¨ LLM ç”Ÿæˆå›å¤ï¼ˆå¤ç”¨ç°æœ‰çš„ getAIResponseï¼Œä½†ä¼ å…¥ç‰¹æ®Šçš„æ¶ˆæ¯ï¼‰
      const aiResponse = await getAIResponse(microActionMessage, conversationHistory, {
        sessionId,
        interactionType: 'micro_action_click',
        metadata: { clickedAction: action },
      });

      // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆè¡¨ç¤ºç”¨æˆ·ç‚¹å‡»äº†æŸä¸ª actionï¼‰
      const userMessage: Message = {
        id: generateId(),
        role: 'user',
        content: `[Clicked on micro-action: ${action.title}]`,
        timestamp: new Date(),
      };
      setMessages((prev) => [...prev, userMessage]);

      // æ·»åŠ  AI å›å¤
      const assistantMessage: Message = {
        id: generateId(),
        role: 'assistant',
        content: aiResponse.message,
        timestamp: new Date(),
        references: aiResponse.references,
      };
      setMessages((prev) => [...prev, assistantMessage]);

      // æ’­æ”¾è¯­éŸ³å›å¤
      playAssistantVoice(aiResponse.message).catch((err) => {
        console.error('Failed to play assistant voice:', err);
      });

      // æ›´æ–°å¾®è¡ŒåŠ¨ï¼ˆLLM å¯èƒ½ä¼šç”Ÿæˆæ–°çš„å¾®è¡ŒåŠ¨ï¼‰
      if (aiResponse.microActions) {
        setCurrentMicroActions(aiResponse.microActions);
      }

      // å¤„ç†éŸ³ä¹è¯·æ±‚
      if (aiResponse.musicRequest?.shouldPlay) {
        handleMusicRequest(aiResponse.musicRequest, assistantMessage.id);
      }

      // æ£€æŸ¥å®‰å…¨çº§åˆ«
      if (aiResponse.safetyLevel !== 'safe') {
        setSafetyLevel(aiResponse.safetyLevel);
        setShowSafetyBanner(true);
      }

      setSessionState('idle');
    } catch (error) {
      console.error('Error handling micro-action click:', error);
      setSessionState('idle');
      alert('Failed to generate response. Please try again.');
    }
  };

  // å¤„ç†éŸ³ä¹è¯·æ±‚ï¼šæœç´¢ YouTube å¹¶æ’­æ”¾
  const handleMusicRequest = async (musicRequest: MusicRequest, triggerMessageId: string) => {
    if (!musicRequest.searchQuery && !musicRequest.youtubeVideoId) {
      return;
    }

    try {
      let resolvedVideoId = musicRequest.youtubeVideoId || null;

      if (!resolvedVideoId && musicRequest.searchQuery) {
        const res = await fetch('/api/youtube-search', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ query: musicRequest.searchQuery }),
        });

        if (!res.ok) {
          console.error('[Session] Failed to search YouTube:', res.status);
          return;
        }

        const data = await res.json();
        resolvedVideoId = data.videoId;
      }

      if (!resolvedVideoId) {
        console.error('[Session] No videoId available for music request');
        return;
      }

      setMusicPlayers((prev) => [
        ...prev,
        {
          id: `music-${Date.now()}-${Math.random().toString(36).slice(2, 7)}`,
          triggerMessageId,
          videoId: resolvedVideoId,
          title: musicRequest.musicType || 'Music',
        },
      ]);
    } catch (error) {
      console.error('[Session] Error searching YouTube:', error);
    }
  };

  const handleCloseMusicPlayer = (playerId: string) => {
    setMusicPlayers((prev) => prev.filter((player) => player.id !== playerId));
  };

  // æ£€æŸ¥æ˜¯å¦å¯ä»¥ç»“æŸä¼šè¯ï¼ˆè‡³å°‘æœ‰ä¸€æ¡AIå›å¤ï¼‰
  const canEndSession = messages.some((m) => m.role === 'assistant');

  // ç»“æŸä¼šè¯
  const handleEndSession = () => {
    if (canEndSession) {
      router.push({
        pathname: '/summary',
        query: {
          messages: JSON.stringify(messages),
          microActions: JSON.stringify(currentMicroActions),
        },
      });
    }
  };

  return (
    <>
      <Head>
        <title>Session - Voice AI Coach</title>
      </Head>

      <div className="min-h-screen flex flex-col bg-gray-50">
        {/* å®‰å…¨æ¨ªå¹… */}
        {showSafetyBanner && (
          <SafetyBanner
            safetyLevel={safetyLevel}
            onDismiss={() => setShowSafetyBanner(false)}
          />
        )}

        {/* éº¦å…‹é£çŠ¶æ€æç¤º */}
        {micError ? (
          <div className="bg-red-50 border-b-2 border-red-500 p-4">
            <div className="max-w-4xl mx-auto">
              <div className="flex items-start justify-between">
                <div className="flex-1">
                  <h3 className="font-semibold text-red-800 mb-2">âš ï¸ Microphone Access Required</h3>
                  <p className="text-sm text-red-700 mb-2">{micError}</p>
                  <div className="text-sm text-red-700">
                    <p className="font-medium mb-1">How to enable microphone access in Chrome:</p>
                    <ul className="list-disc list-inside space-y-1 ml-2">
                      <li>Look for the lock icon (ğŸ”’) or microphone icon (ğŸ¤) in Chrome's address bar</li>
                      <li>Click on it and select "Allow" for microphone permissions</li>
                      <li>Or go to Chrome Settings â†’ Privacy and security â†’ Site Settings â†’ Microphone</li>
                      <li>Find this site and set it to "Allow"</li>
                      <li>Refresh the page and try again</li>
                    </ul>
                  </div>
                </div>
                <button
                  onClick={async () => {
                    setMicError(null);
                    // ä½¿ç”¨ChromeåŸç”Ÿæ–¹æ³•é‡æ–°è¯·æ±‚æƒé™
                    const stream = await requestMicrophoneAccess();
                    if (!stream) {
                      // é”™è¯¯å·²ç»åœ¨requestMicrophoneAccessä¸­è®¾ç½®
                      return;
                    }
                  }}
                  className="ml-4 px-3 py-1 text-sm text-red-700 hover:bg-red-100 rounded"
                >
                  Retry
                </button>
              </div>
            </div>
          </div>
        ) : micReady ? (
          <div className="bg-green-50 border-b-2 border-green-500 p-3">
            <div className="max-w-4xl mx-auto">
              <p className="text-sm text-green-700 text-center">
                âœ… Microphone ready - You can start recording now
              </p>
            </div>
          </div>
        ) : (
          <div className="bg-blue-50 border-b-2 border-blue-500 p-3">
            <div className="max-w-4xl mx-auto">
              <p className="text-sm text-blue-700 text-center">
                ğŸ¤ Requesting microphone access...
              </p>
            </div>
          </div>
        )}

        {/* é¡¶éƒ¨æ  */}
        <header className="bg-white border-b border-gray-200 px-4 py-3">
          <div className="max-w-4xl mx-auto flex items-center justify-between">
            <h1 className="text-xl font-semibold text-gray-900">Voice AI Coach</h1>
            {canEndSession && (
              <button
                onClick={handleEndSession}
                className="px-4 py-2 text-sm text-gray-600 hover:text-gray-900 hover:bg-gray-100 rounded-lg transition-colors"
              >
                End Session
              </button>
            )}
          </div>
        </header>

        {/* æ¶ˆæ¯åˆ—è¡¨åŒºåŸŸ */}
        <div className="flex-1 overflow-hidden">
          <MessageList
            messages={messages}
            microActions={currentMicroActions}
            onMicroActionClick={handleMicroActionClick}
            musicPlayers={musicPlayers}
            onCloseMusicPlayer={handleCloseMusicPlayer}
          />
        </div>

        {/* åº•éƒ¨è¾“å…¥ä¸éº¦å…‹é£åŒºåŸŸ */}
        <div className="bg-white border-t border-gray-200 px-4 py-6">
          <div className="max-w-4xl mx-auto space-y-4">
            <form onSubmit={handleSubmitTypedMessage} className="flex gap-3">
              <input
                type="text"
                value={typedMessage}
                onChange={(e) => setTypedMessage(e.target.value)}
                placeholder="Prefer typing? Share what's on your mind..."
                className="flex-1 rounded-xl border border-gray-200 px-4 py-3 text-sm focus:outline-none focus:ring-2 focus:ring-indigo-400"
                autoComplete="off"
                aria-label="Type your message"
                disabled={sessionState !== 'idle'}
              />
              <button
                type="submit"
                className="px-6 py-3 bg-indigo-600 text-white rounded-xl text-sm font-semibold hover:bg-indigo-700 disabled:opacity-60 disabled:cursor-not-allowed transition-colors"
                disabled={sessionState !== 'idle' || typedMessage.trim().length === 0}
              >
                Send
              </button>
            </form>
            <div className="flex justify-center">
              <MicButton
                state={sessionState}
                onStartRecording={handleStartRecording}
                onStopRecording={handleStopRecording}
              />
            </div>
          </div>
        </div>
      </div>
    </>
  );
}
